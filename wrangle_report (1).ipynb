{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reporting: wrangle_report\n",
    "\n",
    "An overview of the wrangling process in the wrangling project.\n",
    "\n",
    "### Part One: Importing Data\n",
    "\n",
    "Three datasets had to be imported.\n",
    "\n",
    "1. The image predictions file was a tsv file and was imported using pd.read_csv.\n",
    "2. The twitter_archive_enhanced file was provided by Udacity and imported and unzipped using Python libraries.\n",
    "3. The additional Twitter data, tweet_json, required the json Python library and then was converted into a pandas dataframe by writing each JSON line one by one into the dataframe. The data was provided by Udacity as I could not obtain a login to a Twitter developer's account.\n",
    "\n",
    "### Part Two: Identifying Issues\n",
    "\n",
    "The issues were identified concerning the last two files.\n",
    "\n",
    "First the files had to be merged into one. This was so that retweet count and favourite count in particular count could be analyzed, among other indicators.\n",
    "\n",
    "Hence first the files were merged on the 'tweet_id' column, using pd.merge(), once the relevant columns were renamed to have the same name. The merged file minus the irrelevant columns (more details below) was named \"twitter_relevant_data\".\n",
    "\n",
    "The issues are listed below and the steps taken to address each are clarified beneath:\n",
    "\n",
    "1. Retweeted images are present in twitter_archive_enhanced.\n",
    "\n",
    "*Steps: the retweeted tweets were dropped using pandas.DataFrame.drop().\n",
    "\n",
    "2. Non-descriptive headers in twitter_archive_enhanced.\n",
    "\n",
    "3. Non-descriptive headers in tweet_json.\n",
    "    \n",
    "*Steps: Both the above were cleaned after the two files were merged and irrelevant columns dropped. The only relevant non-descriptive header left was 'lang', which was renamed to 'language'. This column showed the language in which each tweet was written.\n",
    "\n",
    "4. The relevant variables favourite count, retweet count and tweet id do not have the same names in tweet_json and twitter_archive_enhanced.\n",
    "\n",
    "*Steps: These were renamed using pd.DataFrame.rename().\n",
    "\n",
    "5. Timestamp column in twitter_archive_enhanced is unparsed.\n",
    "\n",
    "*Step: the 'created_at' column was dropped so only the 'timestamp' column was used. Then pd.to_datetime was used to convert all timestamps to the pandas datetime format. This was checked using DataFrame.info().\n",
    "\n",
    "6. Created_at column in tweet_json is unparsed.\n",
    "\n",
    "*Step: Same as above.\n",
    "\n",
    "7. Column names timestamp and created_at do not match.\n",
    "\n",
    "*Step: As above, 'created_at' was dropped as it is identical to 'timestamp'.\n",
    "\n",
    "8. Ratings data is uncorroborated.\n",
    "\n",
    "*Steps: The corroboration was performed by creating a new column called 'rating', which was a list of fractions with the rating_numerator and rating_denominator as the numerator and denominator, respectively. To do this, a new column was created called 'slash', containing a forward slash in each row. Then rate_numerator and rate_denominator were converted to string format. The three columns' contents were added to create a column of ratings. \n",
    "\n",
    "*For example: if rating_numerator = 10, and rating_denominator = 10, then these were converted to strings and concatenated to create the string '10/10'.\n",
    "\n",
    "9. A tidiness issue. As detailed above, the twitter files were combined into twitter_relevant_data. This was performed before any of the other steps.\n",
    "\n",
    "10. The columns 'doggo', 'puppo', 'pupper', 'floofer' were all dog stages. In the WeRateDogs tweets these indicate different dog stages. They were combined into a single column called 'dog_stage'. \n",
    "\n",
    "*To combine them, the contents of the four columns were concatenated to form strings. E.g. \"None\", \"None\", \"puppo\", \"None\" became a single column entry \"NoneNonepuppoNone\". \n",
    "\n",
    "*Then the new dog_stage column was visually assessed using .value_counts(). This showed that it was full of values such as \"NoneNoneNoneNone\", \"NoneNonepuppoNone\", \"NonepupperNoneNone\", which are unclear. \n",
    "\n",
    "*Clearly the entry \"NonepupperNoneNone\" indicates that the dog_stage was actually \"pupper\". So for each dog_stage entry where there were three \"None\"'s and one actual dog stage, the entry was replaced by the dog stage only. These were replaced using a pandas DataFrame condition.\n",
    "\n",
    "*However there were entries such as \"doggoNonepuppoNone\", where users were undecided about the dog stage. These rows were dropped from the dataset because they do not indicate clearly which dog stage is present in the tweet. Also, this could be a misreading and actually the tweet_json and twitter_enhanced_archive datasets may be disagreeing here. Either way they do not belong in the cleaned dataset (unless the project's goal were to investigate the consistency of dog_stage classification . . . which it was not!). \n",
    "\n",
    "*Finally, the original columns were dropped from the dataset using pd.DataFrame.drop(). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping Irrelevant Columns\n",
    "\n",
    "Some irrelevant columns were dropped. All the relevant columns are listed below. Columns were classed as irrelevant mostly because they replicated other columns. E.g. \"id_str\" is only a list of strings of the id. We already have \"id\", which was an int64 column, and so \"id_str\" was irrelevant.\n",
    "\n",
    "Relevant columns: ['favorite_count',\n",
    "'retweet_count',\n",
    "'quoted_status_id',\n",
    "'retweeted_status',\n",
    "'doggo',\n",
    "'floofer',\n",
    "'puppo',\n",
    "'pupper',\n",
    "'retweeted_status_id',\n",
    "'lang',\n",
    "'full_text',\n",
    "'entities',\n",
    "'created_at',\n",
    "'timestamp',\n",
    "'rating_numerator',\n",
    "'rating_denominator',\n",
    "'text']\n",
    "\n",
    "### Storing the cleaned dataframe\n",
    "\n",
    "The dataframe was stored as a .csv file using pd.to_csv()."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
